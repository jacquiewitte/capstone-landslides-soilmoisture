{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0ed63d0",
   "metadata": {},
   "source": [
    "# Earth Lab Capstone Project: Where can soil moisture improve rainfall-triggered landslide predictability?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6ca49f",
   "metadata": {},
   "source": [
    "## Author: Jacquelyn Witte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250c1e46",
   "metadata": {},
   "source": [
    "## This Notebook exports data from SMAP and ESA CCI soil moisture and GPM daily and IMERG 30min precipitation co-located to Landslides in the US\n",
    "\n",
    "- Based on 2015-2020 Landslide events from the NASA Global Landslide Catalog (GLC)\n",
    "- Using Landslide locations over Colorado as a workflow example\n",
    "- Workflow can be applied to any USA state defined in the GLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "829c65c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Override saving plots\n",
    "GLOBAL_CACHE_OVERRIDE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0b8c4c7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import datetime as dt\n",
    "import earthpy as et\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import xarray as xr\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9784eed4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def read_smap(filepath, index):\n",
    "    \"\"\"\n",
    "    Reads SMAP data and returns the variable of interest.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filepath: Str\n",
    "        File path of a SMAP L3 HDF5 file\n",
    "        \n",
    "    group_id: String\n",
    "        Groups within the file to access\n",
    "        \n",
    "    index: int\n",
    "        Index associated with the variable to retrieve\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    data: 2D numpy.ndarray (lat, lon)\n",
    "    date: Date String yyyymmdd\n",
    "    \"\"\"\n",
    "    # Read the file\n",
    "    group_id = 'Soil_Moisture_Retrieval_Data_PM'\n",
    "    with h5py.File(filepath, 'r') as f:\n",
    "        # Extract data info\n",
    "        data_id = list(f[group_id].keys())[index]\n",
    "        data = f[group_id][data_id][:,:]\n",
    "        data[data == f[group_id][data_id].attrs['_FillValue']] = np.nan\n",
    "        \n",
    "        filename = os.path.basename(filepath)\n",
    "        yyyymmdd= filename.split('_')[5]\n",
    "        yyyy = int(yyyymmdd[0:4])\n",
    "        mm = int(yyyymmdd[4:6])\n",
    "        dd = int(yyyymmdd[6:8])\n",
    "        date=dt.datetime(yyyy,mm,dd)\n",
    "    return data, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bd5b5ae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def findfile(input_files, input_date):\n",
    "    \"\"\"\n",
    "    Returns a single file from a list of files.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_files: List of strings\n",
    "        List of full path to the file\n",
    "        \n",
    "    input_date: String\n",
    "        YYYYMMDD format\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    file: Str\n",
    "    \"\"\"\n",
    "    file = [x for x in input_files if re.findall(input_date, x)]\n",
    "    if not file:\n",
    "        raise ValueError('File does not exist for '+input_date)\n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb117d2c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def nearestneighbor_ncdf(input_file, parameter, loc):\n",
    "    \"\"\"\n",
    "    Extracts nearest neighbor value based on location and desired parameter. \n",
    "    \n",
    "    Parameters\n",
    "    ----------   \n",
    "    input_file: Str - full path to a single file\n",
    "    \n",
    "    parameter: Str \n",
    "    \n",
    "    loc: tuple (degree longtitude, degree latitude)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "    \"\"\"\n",
    "    # read the netcdf file\n",
    "    try:\n",
    "        data_xr = xr.open_dataset(input_file).squeeze()\n",
    "    except IOError:\n",
    "        print(\"This file is not accessible: \"+input_file)\n",
    "    finally:\n",
    "        data_xr.close()\n",
    "    \n",
    "    # subset the file\n",
    "    res = data_xr[parameter].sel(indexers={\n",
    "            'lon': loc[0],\n",
    "            'lat': loc[1]},\n",
    "            method=\"nearest\")\n",
    "    \n",
    "    return float(res.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88502a1f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_imerg_hires(imerg_files, glc_df):\n",
    "    \"\"\"\n",
    "    Reads all IMERG 30min CSV file into a dataFrame.\n",
    "    \n",
    "    # Ref: https://www.geeksforgeeks.org/ways-to-filter-pandas-dataframe-by-column-values/\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    imerg_files: List of strings\n",
    "        List of full path to the file\n",
    "    \n",
    "    glc_df: dataFrame\n",
    "        Global Landslide Catalog \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    imerg: dataFrame\n",
    "        Contains datetime, landslide ID, precipitation\n",
    "\n",
    "    \"\"\"\n",
    "    id_list = glc_df['event_id'].values.tolist()\n",
    "    \n",
    "    list = []\n",
    "    for f in imerg_files:\n",
    "        print(f)\n",
    "        temp_df = pd.read_csv(f)\n",
    "        # filter for landslide id\n",
    "        list.append(temp_df[temp_df['id'].isin(id_list)])\n",
    "\n",
    "    imerg = pd.concat(list)\n",
    "    # convert datetime to pd datetime because some dates are not in the right format\n",
    "    imerg['datetime'] = pd.to_datetime(imerg['datetime'])\n",
    "    # Create a simple date string to compare with the GLC data\n",
    "    imerg['yyyymmdd'] = pd.to_datetime(imerg['datetime']).dt.strftime('%Y%m%d')\n",
    "    #imerg.index = pd.to_datetime(imerg.index)\n",
    "    imerg = imerg.reset_index().set_index('datetime')\n",
    "    return imerg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9bdb63",
   "metadata": {},
   "source": [
    "### Choose the US state "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "850deda2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "westernUS = ['Colorado', 'Utah', 'Idaho',\n",
    "             'California', 'Oregon', 'Washington']\n",
    "state = westernUS[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd2a957",
   "metadata": {},
   "source": [
    "### Read and subset to Landslides >= year 2015 (SMAP data starts in 2015)\n",
    "- Based on the state chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcbb95b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(71, 31)\n",
      "['continuous_rain' 'downpour' 'flooding' 'rain']\n",
      "['debris_flow' 'landslide' 'mudslide' 'rock_fall' 'rotational_slide']\n",
      "Index(['OBJECTID', 'Shape', 'source_name', 'source_link', 'event_id',\n",
      "       'event_date', 'event_time', 'event_title', 'event_description',\n",
      "       'location_description', 'location_accuracy', 'landslide_category',\n",
      "       'landslide_trigger', 'landslide_size', 'landslide_setting',\n",
      "       'fatality_count', 'injury_count', 'storm_name', 'photo_link',\n",
      "       'comments', 'event_import_source', 'event_import_id', 'latitude',\n",
      "       'longitude', 'country_name', 'country_code', 'admin_division_name',\n",
      "       'gazetteer_closest_point', 'gazetteer_distance', 'submitted_date',\n",
      "       'last_edited_date'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>Shape</th>\n",
       "      <th>source_name</th>\n",
       "      <th>source_link</th>\n",
       "      <th>event_id</th>\n",
       "      <th>event_date</th>\n",
       "      <th>event_time</th>\n",
       "      <th>event_title</th>\n",
       "      <th>event_description</th>\n",
       "      <th>location_description</th>\n",
       "      <th>...</th>\n",
       "      <th>event_import_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>country_name</th>\n",
       "      <th>country_code</th>\n",
       "      <th>admin_division_name</th>\n",
       "      <th>gazetteer_closest_point</th>\n",
       "      <th>gazetteer_distance</th>\n",
       "      <th>submitted_date</th>\n",
       "      <th>last_edited_date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-27 18:00:00</th>\n",
       "      <td>7979511</td>\n",
       "      <td>(-123.89150319899994, 45.56208131200003)</td>\n",
       "      <td>KREM Channel 2</td>\n",
       "      <td>http://www.krem.com/news/one-lane-of-highway-1...</td>\n",
       "      <td>11227</td>\n",
       "      <td>2018-01-27 18:00:00</td>\n",
       "      <td>18:00</td>\n",
       "      <td>Hwy 101 south Garibaldi Landslide</td>\n",
       "      <td>400-500 cubic yards of rock and mud came down ...</td>\n",
       "      <td>Milepost 57, US-101, Bay City, Oregon, 97107</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.562081</td>\n",
       "      <td>-123.891503</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Rockaway</td>\n",
       "      <td>5.99</td>\n",
       "      <td>2018-01-30 15:03:38</td>\n",
       "      <td>2022-04-23 06:37:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-30 00:00:00</th>\n",
       "      <td>7986587</td>\n",
       "      <td>(-122.34600236499995, 45.51805393300003)</td>\n",
       "      <td>KATU Channel 2</td>\n",
       "      <td>http://katu.com/news/local/rock-slide-temporar...</td>\n",
       "      <td>12711</td>\n",
       "      <td>2018-04-30 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Historic Columbia River Highway small rockslide</td>\n",
       "      <td>A small rockslide disrupted traffic near Corbe...</td>\n",
       "      <td>30701 E Historic Columbia River Hwy, Troutdale...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.518054</td>\n",
       "      <td>-122.346002</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Portland Troutdale</td>\n",
       "      <td>5.44</td>\n",
       "      <td>2018-06-06 13:41:55</td>\n",
       "      <td>2022-04-23 06:42:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-11 00:00:00</th>\n",
       "      <td>7985597</td>\n",
       "      <td>(-122.23650199999997, 44.10200500000008)</td>\n",
       "      <td>KLCC 89.7</td>\n",
       "      <td>http://klcc.org/post/crews-continue-removing-r...</td>\n",
       "      <td>11321</td>\n",
       "      <td>2018-05-11 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rock slide on Forest Road 19 Blocks Access to ...</td>\n",
       "      <td>8000 cubic yards (6116 cubic meters) of rock f...</td>\n",
       "      <td>Forest Road 19 (Aufderheide Drive), Willamette...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.102005</td>\n",
       "      <td>-122.236502</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>McKenzie Bridge</td>\n",
       "      <td>10.06</td>\n",
       "      <td>2018-05-11 16:07:51</td>\n",
       "      <td>2022-04-23 06:41:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-25 00:00:00</th>\n",
       "      <td>7990447</td>\n",
       "      <td>(-122.47909649199994, 45.39585714300006)</td>\n",
       "      <td>The Bull 98.7</td>\n",
       "      <td>https://www.987thebull.com/rock-slide-closes-h...</td>\n",
       "      <td>13294</td>\n",
       "      <td>2018-12-25 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Highway 224 Rock fall near Tong Road</td>\n",
       "      <td>A rock slide has closed Highway 224, near Tong...</td>\n",
       "      <td>17857-17907 OR-224, Damascus, Oregon, 97089</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.395857</td>\n",
       "      <td>-122.479096</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Oregon City</td>\n",
       "      <td>11.35</td>\n",
       "      <td>2019-01-23 02:11:43</td>\n",
       "      <td>2022-04-23 06:45:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-28 17:00:00</th>\n",
       "      <td>7982616</td>\n",
       "      <td>(-122.16305099099998, 44.73584586900006)</td>\n",
       "      <td>KGW8</td>\n",
       "      <td>https://www.kgw.com/article/traffic/highway-22...</td>\n",
       "      <td>13297</td>\n",
       "      <td>2018-12-28 17:00:00</td>\n",
       "      <td>17:00</td>\n",
       "      <td>Highway 22 Rockslide west of Detroit</td>\n",
       "      <td>300 yards of rocks slid town onto Highway 22, ...</td>\n",
       "      <td>OR-22, Detroit, Oregon, 97342</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.735846</td>\n",
       "      <td>-122.163051</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Detroit Lake</td>\n",
       "      <td>14.77</td>\n",
       "      <td>2019-01-22 16:46:36</td>\n",
       "      <td>2022-04-23 06:39:56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     OBJECTID                                     Shape  \\\n",
       "date                                                                      \n",
       "2018-01-27 18:00:00   7979511  (-123.89150319899994, 45.56208131200003)   \n",
       "2018-04-30 00:00:00   7986587  (-122.34600236499995, 45.51805393300003)   \n",
       "2018-05-11 00:00:00   7985597  (-122.23650199999997, 44.10200500000008)   \n",
       "2018-12-25 00:00:00   7990447  (-122.47909649199994, 45.39585714300006)   \n",
       "2018-12-28 17:00:00   7982616  (-122.16305099099998, 44.73584586900006)   \n",
       "\n",
       "                        source_name  \\\n",
       "date                                  \n",
       "2018-01-27 18:00:00  KREM Channel 2   \n",
       "2018-04-30 00:00:00  KATU Channel 2   \n",
       "2018-05-11 00:00:00       KLCC 89.7   \n",
       "2018-12-25 00:00:00   The Bull 98.7   \n",
       "2018-12-28 17:00:00            KGW8   \n",
       "\n",
       "                                                           source_link  \\\n",
       "date                                                                     \n",
       "2018-01-27 18:00:00  http://www.krem.com/news/one-lane-of-highway-1...   \n",
       "2018-04-30 00:00:00  http://katu.com/news/local/rock-slide-temporar...   \n",
       "2018-05-11 00:00:00  http://klcc.org/post/crews-continue-removing-r...   \n",
       "2018-12-25 00:00:00  https://www.987thebull.com/rock-slide-closes-h...   \n",
       "2018-12-28 17:00:00  https://www.kgw.com/article/traffic/highway-22...   \n",
       "\n",
       "                     event_id           event_date event_time  \\\n",
       "date                                                            \n",
       "2018-01-27 18:00:00     11227  2018-01-27 18:00:00      18:00   \n",
       "2018-04-30 00:00:00     12711  2018-04-30 00:00:00        NaN   \n",
       "2018-05-11 00:00:00     11321  2018-05-11 00:00:00        NaN   \n",
       "2018-12-25 00:00:00     13294  2018-12-25 00:00:00        NaN   \n",
       "2018-12-28 17:00:00     13297  2018-12-28 17:00:00      17:00   \n",
       "\n",
       "                                                           event_title  \\\n",
       "date                                                                     \n",
       "2018-01-27 18:00:00                  Hwy 101 south Garibaldi Landslide   \n",
       "2018-04-30 00:00:00    Historic Columbia River Highway small rockslide   \n",
       "2018-05-11 00:00:00  Rock slide on Forest Road 19 Blocks Access to ...   \n",
       "2018-12-25 00:00:00               Highway 224 Rock fall near Tong Road   \n",
       "2018-12-28 17:00:00               Highway 22 Rockslide west of Detroit   \n",
       "\n",
       "                                                     event_description  \\\n",
       "date                                                                     \n",
       "2018-01-27 18:00:00  400-500 cubic yards of rock and mud came down ...   \n",
       "2018-04-30 00:00:00  A small rockslide disrupted traffic near Corbe...   \n",
       "2018-05-11 00:00:00  8000 cubic yards (6116 cubic meters) of rock f...   \n",
       "2018-12-25 00:00:00  A rock slide has closed Highway 224, near Tong...   \n",
       "2018-12-28 17:00:00  300 yards of rocks slid town onto Highway 22, ...   \n",
       "\n",
       "                                                  location_description  ...  \\\n",
       "date                                                                    ...   \n",
       "2018-01-27 18:00:00       Milepost 57, US-101, Bay City, Oregon, 97107  ...   \n",
       "2018-04-30 00:00:00  30701 E Historic Columbia River Hwy, Troutdale...  ...   \n",
       "2018-05-11 00:00:00  Forest Road 19 (Aufderheide Drive), Willamette...  ...   \n",
       "2018-12-25 00:00:00        17857-17907 OR-224, Damascus, Oregon, 97089  ...   \n",
       "2018-12-28 17:00:00                      OR-22, Detroit, Oregon, 97342  ...   \n",
       "\n",
       "                    event_import_id   latitude   longitude   country_name  \\\n",
       "date                                                                        \n",
       "2018-01-27 18:00:00             NaN  45.562081 -123.891503  United States   \n",
       "2018-04-30 00:00:00             NaN  45.518054 -122.346002  United States   \n",
       "2018-05-11 00:00:00             NaN  44.102005 -122.236502  United States   \n",
       "2018-12-25 00:00:00             NaN  45.395857 -122.479096  United States   \n",
       "2018-12-28 17:00:00             NaN  44.735846 -122.163051  United States   \n",
       "\n",
       "                    country_code  admin_division_name  \\\n",
       "date                                                    \n",
       "2018-01-27 18:00:00           US               Oregon   \n",
       "2018-04-30 00:00:00           US               Oregon   \n",
       "2018-05-11 00:00:00           US               Oregon   \n",
       "2018-12-25 00:00:00           US               Oregon   \n",
       "2018-12-28 17:00:00           US               Oregon   \n",
       "\n",
       "                     gazetteer_closest_point gazetteer_distance  \\\n",
       "date                                                              \n",
       "2018-01-27 18:00:00                 Rockaway               5.99   \n",
       "2018-04-30 00:00:00       Portland Troutdale               5.44   \n",
       "2018-05-11 00:00:00          McKenzie Bridge              10.06   \n",
       "2018-12-25 00:00:00              Oregon City              11.35   \n",
       "2018-12-28 17:00:00             Detroit Lake              14.77   \n",
       "\n",
       "                          submitted_date     last_edited_date  \n",
       "date                                                           \n",
       "2018-01-27 18:00:00  2018-01-30 15:03:38  2022-04-23 06:37:53  \n",
       "2018-04-30 00:00:00  2018-06-06 13:41:55  2022-04-23 06:42:31  \n",
       "2018-05-11 00:00:00  2018-05-11 16:07:51  2022-04-23 06:41:52  \n",
       "2018-12-25 00:00:00  2019-01-23 02:11:43  2022-04-23 06:45:09  \n",
       "2018-12-28 17:00:00  2019-01-22 16:46:36  2022-04-23 06:39:56  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the GLC file\n",
    "glc_file = os.path.join(et.io.HOME,\n",
    "                        'earth-analytics',\n",
    "                        'data', 'capstone', \n",
    "                        'landslide', 'nasa_global_landslide_catalog_point.csv')\n",
    "\n",
    "glc = pd.read_csv(glc_file)\n",
    "\n",
    "glc_state = glc[(glc['country_code'] == 'US') \n",
    "             & (glc['admin_division_name'] == state) \n",
    "             & (glc['landslide_trigger'] != 'freeze_thaw') \n",
    "             & (glc['landslide_trigger'] != 'snowfall_snowmelt') \n",
    "             & (glc['landslide_trigger'] != 'earthquake') \n",
    "             & (glc['landslide_trigger'] != 'leaking_pipe') \n",
    "             & (glc['landslide_trigger'] != 'no_apparent_trigger') \n",
    "             & (glc['landslide_trigger'] != 'other')              \n",
    "             & (glc['landslide_trigger'] != 'unknown')\n",
    "            ]\n",
    "# convert to pandas datetime\n",
    "glc_state['date'] = pd.to_datetime(glc_state['event_date'])\n",
    "glc_state = glc_state.set_index('date').sort_index()\n",
    "glc_state_gt2015 = glc_state[glc_state.index > '2015-04-01']\n",
    "\n",
    "print(glc_state_gt2015.shape)\n",
    "print(np.unique(glc_state_gt2015['landslide_trigger']))\n",
    "print(np.unique(glc_state_gt2015['landslide_category']))\n",
    "print(glc_state_gt2015.columns)\n",
    "\n",
    "# Dropping last dataframe if state=Utah - SMAP data does not exist\n",
    "if state == 'Utah':\n",
    "    glc_state_gt2015 = glc_state_gt2015.drop(pd.to_datetime(\n",
    "                                                        '2019-06-26 04:00:00'))\n",
    "\n",
    "glc_state_gt2015.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd883ca8",
   "metadata": {},
   "source": [
    "### Get all SMAP, ESA, GPM and IMERG data files, sorted\n",
    " - ESA = Percent of Saturation Soil Moisture\n",
    " - SMAP = Volumetric soil moisture in cm3/cm3\n",
    " - GPM = Daily precipitation in mm\n",
    " - IMERG = 30 min precipitation in mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "879b569d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.path.join(et.io.HOME,\n",
    "                        'earth-analytics',\n",
    "                        'data', 'capstone')\n",
    "smap_files = sorted(glob(os.path.join(data_dir, 'smap_9km', '*.h5')))\n",
    "\n",
    "# GPM daily files\n",
    "gpm_files = sorted(glob(os.path.join(data_dir, 'gpm_westernUS', '*nc4')))\n",
    "\n",
    "# GPM 30 min files\n",
    "gpm_hires_files = sorted(glob(os.path.join(data_dir,\n",
    "                                           'precip_imerg',\n",
    "                                           'imerge',\n",
    "                                           'glc', 'imerge*.csv')))\n",
    "\n",
    "esa_files = sorted(glob(os.path.join(data_dir, 'esa_soil_moisture',\n",
    "                                     '*ACTIVE*nc')))\n",
    "\n",
    "# Print a sample as a sanity check\n",
    "print(os.path.exists(smap_files[0]))\n",
    "print(os.path.exists(gpm_files[0]))\n",
    "print(os.path.exists(gpm_hires_files[0]))\n",
    "print(os.path.exists(esa_files[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b7d1a1",
   "metadata": {},
   "source": [
    "### Load the EASE2 grid lon and lat datasets to subset SMAP data. \n",
    "- These can be found on the NSIDC website: https://nsidc.org/data/ease/tools#geo_data_files\n",
    "\n",
    "> Brodzik, M. J., B. Billingsley, T. Haran, B. Raup, M. H. Savoie. 2012. EASE-Grid 2.0: Incremental but Significant Improvements for Earth-Gridded Data Sets. ISPRS International Journal of Geo-Information, 1(1):32-45, doi:10.3390/ijgi1010032. http://www.mdpi.com/2220-9964/1/1/32."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d30c6e1",
   "metadata": {},
   "source": [
    "#### These are SMAP variables that can provide key information in characterizing landslides over Colorado\n",
    "\n",
    "| Variable Name | Index | Units |\n",
    "| ----------- | ----------- | ----------- |\n",
    "| soil_moisture | 24 | cm<sup>3</sup>/cm<sup>3</sup> |\n",
    "| radar_water_body_fraction | 15 | N/A | \n",
    "| vegetation_opacity | 46 | N/A |\n",
    "| vegetation_water_content | 50 | kg/m<sup>2</sup> |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c959ee75",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1624, 3856)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape to dimensions of the SMAP data above\n",
    "sm_data, date = read_smap(smap_files[1], 24)\n",
    "\n",
    "lats = np.fromfile(os.path.join(data_dir, 'smap_9km',\n",
    "                                'EASE2_M09km.lats.3856x1624x1.double'),\n",
    "                   dtype=np.float64).reshape(sm_data.shape)\n",
    "lons = np.fromfile(os.path.join(data_dir, 'smap_9km',\n",
    "                                'EASE2_M09km.lons.3856x1624x1.double'),\n",
    "                   dtype=np.float64).reshape(sm_data.shape)\n",
    "sm_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f072f67",
   "metadata": {},
   "source": [
    "### Read the SMAP, ESA CCI and GPM data \n",
    "- Two dataframes are generated\n",
    "    1. Colocated to all the Landslide events\n",
    "    2. Precipitation measurements going back 7 day from each landslide event and indexed to Landslide ID\n",
    "        - GPM daily resolution precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b573d356",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "precip7d_date = []\n",
    "precip7d = []\n",
    "precip_accum = []\n",
    "precip_max = []\n",
    "smap_sm = []\n",
    "smap_sm_7d = []\n",
    "smap_wc = []\n",
    "esa_sm = []\n",
    "esa_sm_7d = []\n",
    "landslide_date = []\n",
    "landslide_id = []\n",
    "landslide7d_id = []\n",
    "landslide_cat = []\n",
    "landslide_trig = []\n",
    "landslide_sz = []\n",
    "lat = []\n",
    "lon = []\n",
    "periods = 7\n",
    "count_down = []\n",
    "\n",
    "for i, ls_date in enumerate(glc_state_gt2015.index):\n",
    "\n",
    "    # Get -7 days from the event\n",
    "    glc_date = pd.date_range(ls_date, periods=periods,\n",
    "                             freq='-1D').strftime('%Y%m%d')\n",
    "\n",
    "    # Append landslide metadata\n",
    "    landslide_date.append(ls_date)\n",
    "    lat.append(glc_state_gt2015.latitude[i])\n",
    "    lon.append(glc_state_gt2015.longitude[i])\n",
    "    landslide_id.append(glc_state_gt2015.event_id[i])\n",
    "    landslide_cat.append(glc_state_gt2015.landslide_category[i])\n",
    "    landslide_trig.append(glc_state_gt2015.landslide_trigger[i])\n",
    "    landslide_sz.append(glc_state_gt2015.landslide_size[i])\n",
    "\n",
    "    # Take the +/- 0.3 deg mean around the Landslide event\n",
    "    N_lat = glc_state_gt2015.latitude[i]+0.15\n",
    "    S_lat = glc_state_gt2015.latitude[i]-0.15\n",
    "    W_lon = glc_state_gt2015.longitude[i]-0.15\n",
    "    E_lon = glc_state_gt2015.longitude[i]+0.15\n",
    "    subset = (lats < N_lat) & (lats > S_lat) & (lons > W_lon) & (lons < E_lon)\n",
    "\n",
    "    # Initialize data\n",
    "    sm_max = []\n",
    "    vegwc_max = []\n",
    "    esa_mean = []\n",
    "    precip = []\n",
    "    countd = periods\n",
    "\n",
    "    # loop over the 7 days\n",
    "    for yyyymmdd in glc_date:\n",
    "\n",
    "        # Find the SMAP file\n",
    "        filesm = findfile(smap_files, yyyymmdd)\n",
    "        # Retrieve the SMAP variables\n",
    "        sm, time_t = read_smap(filesm[0], 24)\n",
    "        vegwc, t = read_smap(filesm[0], 50)\n",
    "        # Calculate the SMAP max\n",
    "        sm_max.append(np.nanmax(sm[subset]))\n",
    "        vegwc_max.append(np.nanmax(vegwc[subset]))\n",
    "\n",
    "        # Get the Landslide location\n",
    "        loc = (glc_state_gt2015.longitude[i], glc_state_gt2015.latitude[i])\n",
    "\n",
    "        # Find the ESA soil moisture file\n",
    "        file_esa = findfile(esa_files, yyyymmdd)\n",
    "        # Get the nearest neighbor value of % soil moisture\n",
    "        res_esa = nearestneighbor_ncdf(file_esa[0], 'sm', loc)\n",
    "        # Replace negative values with NaN\n",
    "        if res_esa < 0.0:\n",
    "            esa_mean.append(np.nan)\n",
    "        else:\n",
    "            esa_mean.append(res_esa)\n",
    "\n",
    "        # find the GPM file\n",
    "        file_gpm = findfile(gpm_files, yyyymmdd)\n",
    "\n",
    "        precip7d.append(nearestneighbor_ncdf(file_gpm[0],\n",
    "                                             'precipitationCal', loc))\n",
    "        landslide7d_id.append(glc_state_gt2015.event_id[i])\n",
    "        # Append the date\n",
    "        precip7d_date.append(yyyymmdd)\n",
    "\n",
    "        precip.append(nearestneighbor_ncdf(file_gpm[0],\n",
    "                                           'precipitationCal', loc))\n",
    "\n",
    "        # Append countdown\n",
    "        count_down.append(countd)\n",
    "        countd -= 1\n",
    "\n",
    "    # Append the summary values for the 7 day period\n",
    "    smap_sm.append(np.nanmax(sm_max))\n",
    "    smap_wc.append(np.nanmax(vegwc_max))\n",
    "    esa_sm.append(np.nanmax(esa_mean))\n",
    "    smap_sm_7d.extend(sm_max)\n",
    "    esa_sm_7d.extend(esa_mean)\n",
    "\n",
    "    # Filter for low or too high precipitation values\n",
    "    if np.nansum(precip) < 0.4:\n",
    "        precip_accum.append(np.nan)\n",
    "        precip_max.append(np.nan)\n",
    "    else:\n",
    "        precip_accum.append(np.nansum(precip))\n",
    "        precip_max.append(np.nanmax(precip))\n",
    "\n",
    "# Create a soils and precip dataFrame\n",
    "landslide_df = pd.DataFrame(smap_sm,\n",
    "                            index=pd.to_datetime(landslide_date),\n",
    "                            columns=['smap_sm'])\n",
    "landslide_df['veg_water_content'] = smap_wc\n",
    "landslide_df['esa_sm_percent'] = esa_sm\n",
    "landslide_df['gpm_7day_accum_mm'] = precip_accum\n",
    "landslide_df['gpm_7day_max_mm'] = precip_max\n",
    "\n",
    "# Add the Landslide metadata\n",
    "landslide_df['glc_lat'] = lat\n",
    "landslide_df['glc_lon'] = lon\n",
    "landslide_df['landslide_id'] = landslide_id\n",
    "landslide_df['landslide_category'] = landslide_cat\n",
    "landslide_df['landslide_trigger'] = landslide_trig\n",
    "landslide_df['landslide_size'] = landslide_sz\n",
    "\n",
    "# Create the 7day precipitation dataFrame\n",
    "landslide_precip7d_df = pd.DataFrame(precip7d,\n",
    "                                     index=pd.to_datetime(precip7d_date),\n",
    "                                     columns=['gpm_precip_mm'])\n",
    "landslide_precip7d_df['landslide_id'] = landslide7d_id\n",
    "landslide_precip7d_df['smap_sm'] = smap_sm_7d\n",
    "landslide_precip7d_df['esa_vol'] = esa_sm_7d\n",
    "\n",
    "\n",
    "# Add the cumulative precipitation\n",
    "accum = []\n",
    "for i, data in landslide_precip7d_df.groupby(\"landslide_id\"):\n",
    "    res = data['gpm_precip_mm'].cumsum().values\n",
    "    if res.max() > 0.4:\n",
    "        accum.extend(np.flip(data['gpm_precip_mm'].cumsum().values))\n",
    "    else:\n",
    "        accum.extend([np.nan]*periods)\n",
    "\n",
    "landslide_precip7d_df['gpm_7day_accum_mm'] = accum\n",
    "landslide_precip7d_df['days-to-landslide'] = count_down\n",
    "landslide_precip7d_df.index.names = ['date']\n",
    "\n",
    "# Add the normalized precipitation\n",
    "accum_norm = []\n",
    "for i, data in landslide_precip7d_df.groupby(\"landslide_id\"):\n",
    "    res = data['gpm_7day_accum_mm']/data['gpm_7day_accum_mm'].mean()\n",
    "    accum_norm.append(res.max())\n",
    "\n",
    "landslide_df['gpm_7day_accum_norm'] = accum_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68fcdc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 497 entries, 2015-08-29 to 2018-12-22\n",
      "Data columns (total 6 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   gpm_precip_mm      497 non-null    float64\n",
      " 1   landslide_id       497 non-null    int64  \n",
      " 2   smap_sm            243 non-null    float32\n",
      " 3   esa_vol            453 non-null    float64\n",
      " 4   gpm_7day_accum_mm  497 non-null    float64\n",
      " 5   days-to-landslide  497 non-null    int64  \n",
      "dtypes: float32(1), float64(3), int64(2)\n",
      "memory usage: 25.2 KB\n"
     ]
    }
   ],
   "source": [
    "landslide_precip7d_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32312b1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 71 entries, 2015-08-29 00:00:00 to 2018-12-28 17:00:00\n",
      "Data columns (total 12 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   smap_sm              71 non-null     float32\n",
      " 1   veg_water_content    71 non-null     float32\n",
      " 2   esa_sm_percent       70 non-null     float64\n",
      " 3   gpm_7day_accum_mm    71 non-null     float64\n",
      " 4   gpm_7day_max_mm      71 non-null     float64\n",
      " 5   glc_lat              71 non-null     float64\n",
      " 6   glc_lon              71 non-null     float64\n",
      " 7   landslide_id         71 non-null     int64  \n",
      " 8   landslide_category   71 non-null     object \n",
      " 9   landslide_trigger    71 non-null     object \n",
      " 10  landslide_size       71 non-null     object \n",
      " 11  gpm_7day_accum_norm  71 non-null     float64\n",
      "dtypes: float32(2), float64(6), int64(1), object(3)\n",
      "memory usage: 6.7+ KB\n"
     ]
    }
   ],
   "source": [
    "landslide_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a59eea",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Add the IMERGE 30min resolution precipitation to the landslide_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a524e72",
   "metadata": {},
   "source": [
    "#### First, read the IMERGE 30min data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa52c4ff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jwitte/earth-analytics/data/capstone/precip_imerg/imerge/glc/imerge.2015.csv\n",
      "/Users/jwitte/earth-analytics/data/capstone/precip_imerg/imerge/glc/imerge.2016.csv\n",
      "/Users/jwitte/earth-analytics/data/capstone/precip_imerg/imerge/glc/imerge.2017.csv\n",
      "/Users/jwitte/earth-analytics/data/capstone/precip_imerg/imerge/glc/imerge.2018.csv\n",
      "/Users/jwitte/earth-analytics/data/capstone/precip_imerg/imerge/glc/imerge.2019.csv\n",
      "/Users/jwitte/earth-analytics/data/capstone/precip_imerg/imerge/glc/imerge.2020.csv\n"
     ]
    }
   ],
   "source": [
    "imerg_30min = get_imerg_hires(gpm_hires_files, glc_state_gt2015)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a233cfc",
   "metadata": {},
   "source": [
    "#### Loop over the newly created landslide_df\n",
    "- Add the sum and the max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f833ef5b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imerg_7day_sum = []\n",
    "imerg_7day_max = []\n",
    "imerg_7day_accum = []\n",
    "imerg_7day_date = []\n",
    "imerg_7day_id = []\n",
    "\n",
    "for i, ls_date in enumerate(landslide_df.index):\n",
    "\n",
    "    glc_date = pd.date_range(ls_date, periods=7,\n",
    "                             freq='-1D').strftime('%Y%m%d').to_list()\n",
    "\n",
    "    # selecting rows based on condition\n",
    "    rslt_df = imerg_30min[\n",
    "                    (imerg_30min['id'] == landslide_df['landslide_id'][i]) &\n",
    "                    imerg_30min['yyyymmdd'].isin(glc_date)\n",
    "                    ]\n",
    "    # first calculate the 7 day precipitation stats\n",
    "    if rslt_df.shape[0] > 0:\n",
    "        imerg_7day_sum.append(rslt_df['precipitation'].sum())\n",
    "        imerg_7day_max.append(rslt_df['precipitation'].max())\n",
    "        # append the 7 day daily values\n",
    "        imerg_7day_accum.extend(rslt_df.precipitation.resample('D').sum())\n",
    "        imerg_7day_date.extend(glc_date)\n",
    "        imerg_7day_id.extend([landslide_df['landslide_id'][i]]*7)\n",
    "    else:\n",
    "        imerg_7day_sum.append(np.nan)\n",
    "        imerg_7day_max.append(np.nan)\n",
    "        imerg_7day_accum.extend([np.nan]*7)\n",
    "        imerg_7day_date.extend(glc_date)\n",
    "        imerg_7day_id.extend([landslide_df['landslide_id'][i]]*7)\n",
    "\n",
    "landslide_df['imerg_7day_accum_mm'] = imerg_7day_sum\n",
    "landslide_df['imerg_7day_max_mm'] = imerg_7day_max\n",
    "landslide_df.index.name = 'date'\n",
    "\n",
    "landslide_precip7d_df['imerg_precip_mm'] = imerg_7day_accum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7db88a64",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gpm_precip_mm</th>\n",
       "      <th>landslide_id</th>\n",
       "      <th>smap_sm</th>\n",
       "      <th>esa_vol</th>\n",
       "      <th>gpm_7day_accum_mm</th>\n",
       "      <th>days-to-landslide</th>\n",
       "      <th>imerg_precip_mm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-08-29</th>\n",
       "      <td>7.145266</td>\n",
       "      <td>7912</td>\n",
       "      <td>0.285622</td>\n",
       "      <td>26.420483</td>\n",
       "      <td>175.279051</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-28</th>\n",
       "      <td>0.565224</td>\n",
       "      <td>7912</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>174.951981</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-27</th>\n",
       "      <td>0.001086</td>\n",
       "      <td>7912</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.506886</td>\n",
       "      <td>160.905293</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-26</th>\n",
       "      <td>0.005000</td>\n",
       "      <td>7912</td>\n",
       "      <td>0.213500</td>\n",
       "      <td>20.557873</td>\n",
       "      <td>135.678568</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-25</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>7912</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.890720</td>\n",
       "      <td>127.122822</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-26</th>\n",
       "      <td>1.151209</td>\n",
       "      <td>13297</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.611134</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-25</th>\n",
       "      <td>0.000088</td>\n",
       "      <td>13297</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.841618</td>\n",
       "      <td>1.952697</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-24</th>\n",
       "      <td>14.658437</td>\n",
       "      <td>13297</td>\n",
       "      <td>0.411319</td>\n",
       "      <td>66.755066</td>\n",
       "      <td>1.952609</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-23</th>\n",
       "      <td>18.691599</td>\n",
       "      <td>13297</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.801400</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-22</th>\n",
       "      <td>0.743509</td>\n",
       "      <td>13297</td>\n",
       "      <td>0.392671</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>497 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            gpm_precip_mm  landslide_id   smap_sm    esa_vol  \\\n",
       "date                                                           \n",
       "2015-08-29       7.145266          7912  0.285622  26.420483   \n",
       "2015-08-28       0.565224          7912       NaN        NaN   \n",
       "2015-08-27       0.001086          7912       NaN  31.506886   \n",
       "2015-08-26       0.005000          7912  0.213500  20.557873   \n",
       "2015-08-25       0.000000          7912       NaN  17.890720   \n",
       "...                   ...           ...       ...        ...   \n",
       "2018-12-26       1.151209         13297       NaN        NaN   \n",
       "2018-12-25       0.000088         13297       NaN  54.841618   \n",
       "2018-12-24      14.658437         13297  0.411319  66.755066   \n",
       "2018-12-23      18.691599         13297       NaN        NaN   \n",
       "2018-12-22       0.743509         13297  0.392671        NaN   \n",
       "\n",
       "            gpm_7day_accum_mm  days-to-landslide  imerg_precip_mm  \n",
       "date                                                               \n",
       "2015-08-29         175.279051                  7              NaN  \n",
       "2015-08-28         174.951981                  6              NaN  \n",
       "2015-08-27         160.905293                  5              NaN  \n",
       "2015-08-26         135.678568                  4              NaN  \n",
       "2015-08-25         127.122822                  3              NaN  \n",
       "...                       ...                ...              ...  \n",
       "2018-12-26          16.611134                  5              NaN  \n",
       "2018-12-25           1.952697                  4              NaN  \n",
       "2018-12-24           1.952609                  3              NaN  \n",
       "2018-12-23           0.801400                  2              NaN  \n",
       "2018-12-22           0.000000                  1              NaN  \n",
       "\n",
       "[497 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landslide_precip7d_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f58fa8",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Export the dataFrame to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce25a87a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# converting to CSV file\n",
    "output_file = os.path.join('data','glc_smap_esa_gpm_2015-2020_'+state+'.csv')\n",
    "landslide_df.to_csv(output_file)\n",
    "\n",
    "output_7d_file = os.path.join('data',\n",
    "                              'glc_smap_esa_gpm_2015-2020_7day_'+state+'.csv')\n",
    "landslide_precip7d_df.to_csv(output_7d_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34eb7fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
