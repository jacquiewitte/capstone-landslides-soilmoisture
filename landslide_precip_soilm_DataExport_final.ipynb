{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0ed63d0",
   "metadata": {},
   "source": [
    "# Earth Lab Capstone Project: Where can soil moisture improve rainfall-triggered landslide predictability?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6ca49f",
   "metadata": {},
   "source": [
    "## Author: Jacquelyn Witte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250c1e46",
   "metadata": {},
   "source": [
    "## This Notebook exports data from SMAP and ESA CCI soil moisture, GPM daily and IMERG 30min precipitation, and POLARIS soil properties co-located to Landslides in the US\n",
    "\n",
    "- Based on 2015-2020 Landslide events from the NASA Global Landslide Catalog (GLC)\n",
    "- Using Landslide locations over Colorado as a workflow example\n",
    "- Workflow can be applied to any USA state defined in the GLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0b8c4c7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import datetime as dt\n",
    "import earthpy as et\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import rioxarray as rxr\n",
    "import xarray as xr\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2462c660",
   "metadata": {},
   "source": [
    "## Begin Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9784eed4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def read_smap(filepath, index):\n",
    "    \"\"\"\n",
    "    Reads SMAP data and returns the variable of interest.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filepath: Str\n",
    "        File path of a SMAP L3 HDF5 file\n",
    "        \n",
    "    group_id: String\n",
    "        Groups within the file to access\n",
    "        \n",
    "    index: int\n",
    "        Index associated with the variable to retrieve\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    data: 2D numpy.ndarray (lat, lon)\n",
    "    date: Date String yyyymmdd\n",
    "    \"\"\"\n",
    "    # Read the file\n",
    "    group_id = 'Soil_Moisture_Retrieval_Data_PM'\n",
    "    with h5py.File(filepath, 'r') as f:\n",
    "        # Extract data info\n",
    "        data_id = list(f[group_id].keys())[index]\n",
    "        data = f[group_id][data_id][:,:]\n",
    "        data[data == f[group_id][data_id].attrs['_FillValue']] = np.nan\n",
    "        \n",
    "        filename = os.path.basename(filepath)\n",
    "        yyyymmdd= filename.split('_')[5]\n",
    "        yyyy = int(yyyymmdd[0:4])\n",
    "        mm = int(yyyymmdd[4:6])\n",
    "        dd = int(yyyymmdd[6:8])\n",
    "        date=dt.datetime(yyyy,mm,dd)\n",
    "    return data, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bd5b5ae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def findfile(input_files, input_date):\n",
    "    \"\"\"\n",
    "    Returns a single file from a list of files.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_files: List of strings\n",
    "        List of full path to the file\n",
    "        \n",
    "    input_date: String\n",
    "        YYYYMMDD format\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    file: Str\n",
    "    \"\"\"\n",
    "    file = [x for x in input_files if re.findall(input_date, x)]\n",
    "    if not file:\n",
    "        raise ValueError('File does not exist for '+input_date)\n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb117d2c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def nearestneighbor_ncdf(input_file, parameter, loc):\n",
    "    \"\"\"\n",
    "    Extracts nearest neighbor value based on location and desired parameter. \n",
    "    \n",
    "    Parameters\n",
    "    ----------   \n",
    "    input_file: Str - full path to a single file\n",
    "    \n",
    "    parameter: Str \n",
    "    \n",
    "    loc: tuple (degree longtitude, degree latitude)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "    \"\"\"\n",
    "    # read the netcdf file\n",
    "    try:\n",
    "        data_xr = xr.open_dataset(input_file).squeeze()\n",
    "    except IOError:\n",
    "        print(\"This file is not accessible: \"+input_file)\n",
    "    finally:\n",
    "        data_xr.close()\n",
    "    \n",
    "    # subset the file\n",
    "    res = data_xr[parameter].sel(indexers={\n",
    "            'lon': loc[0],\n",
    "            'lat': loc[1]},\n",
    "            method=\"nearest\")\n",
    "    \n",
    "    return float(res.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88502a1f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_imerg_hires(imerg_files, glc_df):\n",
    "    \"\"\"\n",
    "    Reads all IMERG 30min CSV file into a dataFrame.\n",
    "    \n",
    "    Ref: https://www.geeksforgeeks.org/ways-to-filter-pandas-dataframe-by-column-values/\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    imerg_files: List of strings\n",
    "        List of full path to the file\n",
    "    \n",
    "    glc_df: dataFrame\n",
    "        Global Landslide Catalog \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    imerg: dataFrame\n",
    "        Contains datetime, landslide ID, precipitation\n",
    "\n",
    "    \"\"\"\n",
    "    id_list = glc_df['event_id'].values.tolist()\n",
    "    \n",
    "    list = []\n",
    "    for f in imerg_files:\n",
    "        print(f)\n",
    "        temp_df = pd.read_csv(f)\n",
    "        # filter for landslide id\n",
    "        list.append(temp_df[temp_df['id'].isin(id_list)])\n",
    "\n",
    "    imerg = pd.concat(list)\n",
    "    # convert datetime to pd datetime because some dates are not in the right format\n",
    "    imerg['datetime'] = pd.to_datetime(imerg['datetime'])\n",
    "    # Create a simple date string to compare with the GLC data\n",
    "    imerg['yyyymmdd'] = pd.to_datetime(imerg['datetime']).dt.strftime('%Y%m%d')\n",
    "    #imerg.index = pd.to_datetime(imerg.index)\n",
    "    imerg = imerg.reset_index().set_index('datetime')\n",
    "    return imerg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b43dfa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_polaris_ksat(lat_in, lon_in):\n",
    "    \"\"\"\n",
    "    Reads POLARIS Ksat value.\n",
    "    \n",
    "    About POLARIS soil variable\n",
    "        - 30 m Ksat (Saturated Hydraulic Conductivity of Soil) \n",
    "        - 5-15 cm mode in log10(cm/hr)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    lat_in, lon_in: float latitude, longitude in degrees\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    ksat_value: float\n",
    "        Uses nearest neighbor method to find closest latitude, longitude coord\n",
    "    \"\"\"\n",
    "    polaris_url = 'http://hydrology.cee.duke.edu/POLARIS/PROPERTIES/v1.0/ksat/mode/5_15/'\n",
    "\n",
    "    # assemble polaris filename\n",
    "    lat_str = str(int(lat_in)) + str(int(lat_in+1))\n",
    "    lon_str = str(int(lon_in-1)) + str(int(lon_in))\n",
    "    filen = 'lat'+lat_str+'_lon'+lon_str+'.tif'\n",
    "    # read the polaris file\n",
    "    polaris_xr = rxr.open_rasterio(polaris_url+filen, masked=True).squeeze()\n",
    "    # subset the polaris file to the nearest lat, lon\n",
    "    ksat_value = polaris_xr.sel(indexers={\n",
    "        'x': lon_in,\n",
    "        'y': lat_in},\n",
    "        method=\"nearest\").values\n",
    "    return float(ksat_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1119d0f",
   "metadata": {},
   "source": [
    "## Start of the main program"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9bdb63",
   "metadata": {},
   "source": [
    "### Choose the US state "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "850deda2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "westernUS = ['Colorado', 'Utah', 'Idaho',\n",
    "             'California', 'Oregon', 'Washington']\n",
    "state = westernUS[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd2a957",
   "metadata": {},
   "source": [
    "### Read and subset to Landslides >= year 2015 (SMAP data starts in 2015)\n",
    "- Based on the state chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcbb95b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124, 31)\n",
      "['continuous_rain' 'downpour' 'flooding' 'rain']\n",
      "['creep' 'debris_flow' 'landslide' 'mudslide' 'riverbank_collapse'\n",
      " 'rock_fall' 'unknown']\n",
      "Index(['OBJECTID', 'Shape', 'source_name', 'source_link', 'event_id',\n",
      "       'event_date', 'event_time', 'event_title', 'event_description',\n",
      "       'location_description', 'location_accuracy', 'landslide_category',\n",
      "       'landslide_trigger', 'landslide_size', 'landslide_setting',\n",
      "       'fatality_count', 'injury_count', 'storm_name', 'photo_link',\n",
      "       'comments', 'event_import_source', 'event_import_id', 'latitude',\n",
      "       'longitude', 'country_name', 'country_code', 'admin_division_name',\n",
      "       'gazetteer_closest_point', 'gazetteer_distance', 'submitted_date',\n",
      "       'last_edited_date'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>Shape</th>\n",
       "      <th>source_name</th>\n",
       "      <th>source_link</th>\n",
       "      <th>event_id</th>\n",
       "      <th>event_date</th>\n",
       "      <th>event_time</th>\n",
       "      <th>event_title</th>\n",
       "      <th>event_description</th>\n",
       "      <th>location_description</th>\n",
       "      <th>...</th>\n",
       "      <th>event_import_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>country_name</th>\n",
       "      <th>country_code</th>\n",
       "      <th>admin_division_name</th>\n",
       "      <th>gazetteer_closest_point</th>\n",
       "      <th>gazetteer_distance</th>\n",
       "      <th>submitted_date</th>\n",
       "      <th>last_edited_date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-27 00:00:00</th>\n",
       "      <td>7965456</td>\n",
       "      <td>(-122.281470636, 47.723066000000074)</td>\n",
       "      <td>KIRO Channel 7</td>\n",
       "      <td>http://www.kiro7.com/news/local/mudslide-trees...</td>\n",
       "      <td>11230</td>\n",
       "      <td>2018-01-27 00:00:00</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Burke-Gilman Trail Slide including 2 Downed Trees</td>\n",
       "      <td>Trail closed between 42nd PL NE and NE 125th d...</td>\n",
       "      <td>Burke-Gilman Trl, Seattle, Washington, 98125</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.723066</td>\n",
       "      <td>-122.281471</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>15.19</td>\n",
       "      <td>2018-01-30 15:03:38</td>\n",
       "      <td>2022-04-23 06:28:10.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-27 04:00:00</th>\n",
       "      <td>7995024</td>\n",
       "      <td>(-123.13163354599999, 47.417838896000035)</td>\n",
       "      <td>KOMO News</td>\n",
       "      <td>http://komonews.com/news/local/mudslide-closes...</td>\n",
       "      <td>11246</td>\n",
       "      <td>2018-01-27 04:00:00</td>\n",
       "      <td>04:00</td>\n",
       "      <td>US 101 Mudslide at Hoodsport, Milepost 330</td>\n",
       "      <td>Mudslide near Cedardale Lane north of Hoodspor...</td>\n",
       "      <td>milepost 330, US-101, Hoodsport, Washington, 9...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.417839</td>\n",
       "      <td>-123.131634</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Cushman Lake</td>\n",
       "      <td>16.80</td>\n",
       "      <td>2018-01-30 15:03:38</td>\n",
       "      <td>2022-04-23 06:23:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-30 00:00:00</th>\n",
       "      <td>7989505</td>\n",
       "      <td>(-122.36491937299996, 47.475680503000035)</td>\n",
       "      <td>B-Town Blog</td>\n",
       "      <td>http://b-townblog.com/2018/01/30/small-landsli...</td>\n",
       "      <td>11252</td>\n",
       "      <td>2018-01-30 00:00:00</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Seahurst Park Landslide south of Sea Star Shelter</td>\n",
       "      <td>A small landslide has occurred south of Sea St...</td>\n",
       "      <td>south of Sea Star Shelter, Seahurst Park</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.475681</td>\n",
       "      <td>-122.364919</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Seattle Tacoma International</td>\n",
       "      <td>5.40</td>\n",
       "      <td>2018-02-08 16:16:12</td>\n",
       "      <td>2022-04-23 06:44:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-12 00:00:00</th>\n",
       "      <td>7977485</td>\n",
       "      <td>(-123.29357847499995, 46.26644980300006)</td>\n",
       "      <td>The Wahkiakum County Eagle</td>\n",
       "      <td>http://www.waheagle.com/story/2018/05/03/news/...</td>\n",
       "      <td>11455</td>\n",
       "      <td>2018-04-12 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Elochoman Valley Road Slow-Moving Landslide</td>\n",
       "      <td>A slow-moving landslide at milepost 7.47 cause...</td>\n",
       "      <td>Milepost 7.47, Elochoman Valley Rd, Cathlamet,...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.266450</td>\n",
       "      <td>-123.293578</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Cathlamet</td>\n",
       "      <td>9.41</td>\n",
       "      <td>2018-06-04 14:58:45</td>\n",
       "      <td>2022-04-23 06:36:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-02 00:00:00</th>\n",
       "      <td>7972437</td>\n",
       "      <td>(-120.97715071999994, 47.16860440900007)</td>\n",
       "      <td>Yakima Herald</td>\n",
       "      <td>http://www.yakimaherald.com/news/local/landsli...</td>\n",
       "      <td>11457</td>\n",
       "      <td>2018-06-02 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mohar Road sinking from landslide</td>\n",
       "      <td>The road is closed at the intersection of Moha...</td>\n",
       "      <td>2657-3299 Mohar Rd, Cle Elum, Washington, 98922</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.168604</td>\n",
       "      <td>-120.977151</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Cle Elum</td>\n",
       "      <td>4.80</td>\n",
       "      <td>2018-06-04 01:17:49</td>\n",
       "      <td>2022-04-23 06:33:06.000001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     OBJECTID                                      Shape  \\\n",
       "date                                                                       \n",
       "2018-01-27 00:00:00   7965456       (-122.281470636, 47.723066000000074)   \n",
       "2018-01-27 04:00:00   7995024  (-123.13163354599999, 47.417838896000035)   \n",
       "2018-01-30 00:00:00   7989505  (-122.36491937299996, 47.475680503000035)   \n",
       "2018-04-12 00:00:00   7977485   (-123.29357847499995, 46.26644980300006)   \n",
       "2018-06-02 00:00:00   7972437   (-120.97715071999994, 47.16860440900007)   \n",
       "\n",
       "                                    source_name  \\\n",
       "date                                              \n",
       "2018-01-27 00:00:00              KIRO Channel 7   \n",
       "2018-01-27 04:00:00                   KOMO News   \n",
       "2018-01-30 00:00:00                 B-Town Blog   \n",
       "2018-04-12 00:00:00  The Wahkiakum County Eagle   \n",
       "2018-06-02 00:00:00               Yakima Herald   \n",
       "\n",
       "                                                           source_link  \\\n",
       "date                                                                     \n",
       "2018-01-27 00:00:00  http://www.kiro7.com/news/local/mudslide-trees...   \n",
       "2018-01-27 04:00:00  http://komonews.com/news/local/mudslide-closes...   \n",
       "2018-01-30 00:00:00  http://b-townblog.com/2018/01/30/small-landsli...   \n",
       "2018-04-12 00:00:00  http://www.waheagle.com/story/2018/05/03/news/...   \n",
       "2018-06-02 00:00:00  http://www.yakimaherald.com/news/local/landsli...   \n",
       "\n",
       "                     event_id           event_date event_time  \\\n",
       "date                                                            \n",
       "2018-01-27 00:00:00     11230  2018-01-27 00:00:00    unknown   \n",
       "2018-01-27 04:00:00     11246  2018-01-27 04:00:00      04:00   \n",
       "2018-01-30 00:00:00     11252  2018-01-30 00:00:00    unknown   \n",
       "2018-04-12 00:00:00     11455  2018-04-12 00:00:00        NaN   \n",
       "2018-06-02 00:00:00     11457  2018-06-02 00:00:00        NaN   \n",
       "\n",
       "                                                           event_title  \\\n",
       "date                                                                     \n",
       "2018-01-27 00:00:00  Burke-Gilman Trail Slide including 2 Downed Trees   \n",
       "2018-01-27 04:00:00         US 101 Mudslide at Hoodsport, Milepost 330   \n",
       "2018-01-30 00:00:00  Seahurst Park Landslide south of Sea Star Shelter   \n",
       "2018-04-12 00:00:00        Elochoman Valley Road Slow-Moving Landslide   \n",
       "2018-06-02 00:00:00                  Mohar Road sinking from landslide   \n",
       "\n",
       "                                                     event_description  \\\n",
       "date                                                                     \n",
       "2018-01-27 00:00:00  Trail closed between 42nd PL NE and NE 125th d...   \n",
       "2018-01-27 04:00:00  Mudslide near Cedardale Lane north of Hoodspor...   \n",
       "2018-01-30 00:00:00  A small landslide has occurred south of Sea St...   \n",
       "2018-04-12 00:00:00  A slow-moving landslide at milepost 7.47 cause...   \n",
       "2018-06-02 00:00:00  The road is closed at the intersection of Moha...   \n",
       "\n",
       "                                                  location_description  ...  \\\n",
       "date                                                                    ...   \n",
       "2018-01-27 00:00:00       Burke-Gilman Trl, Seattle, Washington, 98125  ...   \n",
       "2018-01-27 04:00:00  milepost 330, US-101, Hoodsport, Washington, 9...  ...   \n",
       "2018-01-30 00:00:00           south of Sea Star Shelter, Seahurst Park  ...   \n",
       "2018-04-12 00:00:00  Milepost 7.47, Elochoman Valley Rd, Cathlamet,...  ...   \n",
       "2018-06-02 00:00:00    2657-3299 Mohar Rd, Cle Elum, Washington, 98922  ...   \n",
       "\n",
       "                    event_import_id   latitude   longitude   country_name  \\\n",
       "date                                                                        \n",
       "2018-01-27 00:00:00             NaN  47.723066 -122.281471  United States   \n",
       "2018-01-27 04:00:00             NaN  47.417839 -123.131634  United States   \n",
       "2018-01-30 00:00:00             NaN  47.475681 -122.364919  United States   \n",
       "2018-04-12 00:00:00             NaN  46.266450 -123.293578  United States   \n",
       "2018-06-02 00:00:00             NaN  47.168604 -120.977151  United States   \n",
       "\n",
       "                    country_code  admin_division_name  \\\n",
       "date                                                    \n",
       "2018-01-27 00:00:00           US           Washington   \n",
       "2018-01-27 04:00:00           US           Washington   \n",
       "2018-01-30 00:00:00           US           Washington   \n",
       "2018-04-12 00:00:00           US           Washington   \n",
       "2018-06-02 00:00:00           US           Washington   \n",
       "\n",
       "                          gazetteer_closest_point gazetteer_distance  \\\n",
       "date                                                                   \n",
       "2018-01-27 00:00:00                       Seattle              15.19   \n",
       "2018-01-27 04:00:00                  Cushman Lake              16.80   \n",
       "2018-01-30 00:00:00  Seattle Tacoma International               5.40   \n",
       "2018-04-12 00:00:00                     Cathlamet               9.41   \n",
       "2018-06-02 00:00:00                      Cle Elum               4.80   \n",
       "\n",
       "                          submitted_date            last_edited_date  \n",
       "date                                                                  \n",
       "2018-01-27 00:00:00  2018-01-30 15:03:38  2022-04-23 06:28:10.000001  \n",
       "2018-01-27 04:00:00  2018-01-30 15:03:38         2022-04-23 06:23:59  \n",
       "2018-01-30 00:00:00  2018-02-08 16:16:12         2022-04-23 06:44:28  \n",
       "2018-04-12 00:00:00  2018-06-04 14:58:45         2022-04-23 06:36:29  \n",
       "2018-06-02 00:00:00  2018-06-04 01:17:49  2022-04-23 06:33:06.000001  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the GLC file\n",
    "glc_file = os.path.join(et.io.HOME,\n",
    "                        'earth-analytics',\n",
    "                        'data', 'capstone', \n",
    "                        'landslide', 'nasa_global_landslide_catalog_point.csv')\n",
    "\n",
    "glc = pd.read_csv(glc_file)\n",
    "\n",
    "glc_state = glc[(glc['country_code'] == 'US') \n",
    "             & (glc['admin_division_name'] == state) \n",
    "             & (glc['landslide_trigger'] != 'freeze_thaw') \n",
    "             & (glc['landslide_trigger'] != 'snowfall_snowmelt') \n",
    "             & (glc['landslide_trigger'] != 'earthquake') \n",
    "             & (glc['landslide_trigger'] != 'leaking_pipe') \n",
    "             & (glc['landslide_trigger'] != 'no_apparent_trigger') \n",
    "             & (glc['landslide_trigger'] != 'other')              \n",
    "             & (glc['landslide_trigger'] != 'unknown')\n",
    "            ]\n",
    "# convert to pandas datetime\n",
    "glc_state['date'] = pd.to_datetime(glc_state['event_date'])\n",
    "glc_state = glc_state.set_index('date').sort_index()\n",
    "glc_state_gt2015 = glc_state[glc_state.index > '2015-04-01']\n",
    "\n",
    "print(glc_state_gt2015.shape)\n",
    "print(np.unique(glc_state_gt2015['landslide_trigger']))\n",
    "print(np.unique(glc_state_gt2015['landslide_category']))\n",
    "print(glc_state_gt2015.columns)\n",
    "\n",
    "# Dropping last dataframe if state=Utah - SMAP data does not exist\n",
    "if state == 'Utah':\n",
    "    glc_state_gt2015 = glc_state_gt2015.drop(pd.to_datetime(\n",
    "                                                        '2019-06-26 04:00:00'))\n",
    "\n",
    "glc_state_gt2015.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd883ca8",
   "metadata": {},
   "source": [
    "### Get all SMAP, ESA, GPM and IMERG data files, sorted\n",
    " - ESA = Percent of Saturation Soil Moisture\n",
    " - SMAP = Volumetric soil moisture in cm3/cm3\n",
    " - GPM = Daily precipitation in mm\n",
    " - IMERG = 30 min precipitation in mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "879b569d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.path.join(et.io.HOME,\n",
    "                        'earth-analytics',\n",
    "                        'data', 'capstone')\n",
    "\n",
    "# SMAP 9km files\n",
    "smap_files = sorted(glob(os.path.join(data_dir, 'smap_9km', '*.h5')))\n",
    "\n",
    "# GPM daily files\n",
    "gpm_files = sorted(glob(os.path.join(data_dir, 'gpm_westernUS', '*nc4')))\n",
    "\n",
    "# GPM 30 min files\n",
    "gpm_hires_files = sorted(glob(os.path.join(data_dir,\n",
    "                                           'precip_imerg',\n",
    "                                           'imerge',\n",
    "                                           'glc', 'imerge*.csv')))\n",
    "\n",
    "# ESA soil volume\n",
    "esa_files = sorted(glob(os.path.join(data_dir, 'esa_soil_moisture',\n",
    "                                     '*ACTIVE*nc')))\n",
    "\n",
    "# Print a sample as a sanity check\n",
    "print(os.path.exists(smap_files[0]))\n",
    "print(os.path.exists(gpm_files[0]))\n",
    "print(os.path.exists(gpm_hires_files[0]))\n",
    "print(os.path.exists(esa_files[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b7d1a1",
   "metadata": {},
   "source": [
    "### Load the EASE2 grid lon and lat datasets to subset SMAP data. \n",
    "- These can be found on the NSIDC website: https://nsidc.org/data/ease/tools#geo_data_files\n",
    "\n",
    "> Brodzik, M. J., B. Billingsley, T. Haran, B. Raup, M. H. Savoie. 2012. EASE-Grid 2.0: Incremental but Significant Improvements for Earth-Gridded Data Sets. ISPRS International Journal of Geo-Information, 1(1):32-45, doi:10.3390/ijgi1010032. http://www.mdpi.com/2220-9964/1/1/32."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d30c6e1",
   "metadata": {},
   "source": [
    "#### These are SMAP variables that can provide key information in characterizing landslides over Colorado\n",
    "\n",
    "| Variable Name | Index | Units |\n",
    "| ----------- | ----------- | ----------- |\n",
    "| soil_moisture | 24 | cm<sup>3</sup>/cm<sup>3</sup> |\n",
    "| radar_water_body_fraction | 15 | N/A | \n",
    "| vegetation_opacity | 46 | N/A |\n",
    "| vegetation_water_content | 50 | kg/m<sup>2</sup> |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c959ee75",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1624, 3856)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape to dimensions of the SMAP data above\n",
    "sm_data, date = read_smap(smap_files[1], 24)\n",
    "\n",
    "lats = np.fromfile(os.path.join(data_dir, 'smap_9km',\n",
    "                                'EASE2_M09km.lats.3856x1624x1.double'),\n",
    "                   dtype=np.float64).reshape(sm_data.shape)\n",
    "lons = np.fromfile(os.path.join(data_dir, 'smap_9km',\n",
    "                                'EASE2_M09km.lons.3856x1624x1.double'),\n",
    "                   dtype=np.float64).reshape(sm_data.shape)\n",
    "sm_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f072f67",
   "metadata": {},
   "source": [
    "### Read the SMAP, ESA CCI and GPM data \n",
    "- Two dataframes are generated\n",
    "    1. Colocated to all the Landslide events\n",
    "    2. Precipitation measurements going back 7 day from each landslide event and indexed to Landslide ID\n",
    "        - GPM daily resolution precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b573d356",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "precip7d_date = []\n",
    "precip7d = []\n",
    "precip_accum = []\n",
    "precip_max = []\n",
    "smap_sm = []\n",
    "smap_sm_7d = []\n",
    "smap_wc = []\n",
    "esa_sm = []\n",
    "esa_sm_7d = []\n",
    "ksat_list = []\n",
    "landslide_date = []\n",
    "landslide_id = []\n",
    "landslide7d_id = []\n",
    "landslide_cat = []\n",
    "landslide_trig = []\n",
    "landslide_sz = []\n",
    "lat = []\n",
    "lon = []\n",
    "periods = 7\n",
    "count_down = []\n",
    "\n",
    "for i, ls_date in enumerate(glc_state_gt2015.index):\n",
    "\n",
    "    # Get -7 days from the event\n",
    "    glc_date = pd.date_range(ls_date, periods=periods,\n",
    "                             freq='-1D').strftime('%Y%m%d')\n",
    "\n",
    "    # Append landslide metadata\n",
    "    landslide_date.append(ls_date)\n",
    "    lat.append(glc_state_gt2015.latitude[i])\n",
    "    lon.append(glc_state_gt2015.longitude[i])\n",
    "    landslide_id.append(glc_state_gt2015.event_id[i])\n",
    "    landslide_cat.append(glc_state_gt2015.landslide_category[i])\n",
    "    landslide_trig.append(glc_state_gt2015.landslide_trigger[i])\n",
    "    landslide_sz.append(glc_state_gt2015.landslide_size[i])\n",
    "\n",
    "    # Append Ksat value\n",
    "    ksat_list.append(get_polaris_ksat(glc_state_gt2015.latitude[i], \n",
    "                     glc_state_gt2015.longitude[i])\n",
    "                    )\n",
    "    \n",
    "    # Take the +/- 0.3 deg mean around the Landslide event for SMAP calculation\n",
    "    N_lat = glc_state_gt2015.latitude[i]+0.15\n",
    "    S_lat = glc_state_gt2015.latitude[i]-0.15\n",
    "    W_lon = glc_state_gt2015.longitude[i]-0.15\n",
    "    E_lon = glc_state_gt2015.longitude[i]+0.15\n",
    "    subset = (lats < N_lat) & (lats > S_lat) & (lons > W_lon) & (lons < E_lon)\n",
    "\n",
    "    # Initialize data\n",
    "    sm_max = []\n",
    "    vegwc_max = []\n",
    "    esa_mean = []\n",
    "    precip = []\n",
    "    countd = periods\n",
    "\n",
    "    # loop over the 7 days\n",
    "    for yyyymmdd in glc_date:\n",
    "\n",
    "        # Find the SMAP file\n",
    "        filesm = findfile(smap_files, yyyymmdd)\n",
    "        # Retrieve the SMAP variables\n",
    "        sm, time_t = read_smap(filesm[0], 24)\n",
    "        vegwc, t = read_smap(filesm[0], 50)\n",
    "        # Calculate the SMAP max\n",
    "        sm_max.append(np.nanmax(sm[subset]))\n",
    "        vegwc_max.append(np.nanmax(vegwc[subset]))\n",
    "\n",
    "        # Get the Landslide location\n",
    "        loc = (glc_state_gt2015.longitude[i], glc_state_gt2015.latitude[i])\n",
    "\n",
    "        # Find the ESA soil moisture file\n",
    "        file_esa = findfile(esa_files, yyyymmdd)\n",
    "        # Get the nearest neighbor value of % soil moisture\n",
    "        res_esa = nearestneighbor_ncdf(file_esa[0], 'sm', loc)\n",
    "        # Replace negative values with NaN\n",
    "        if res_esa < 0.0:\n",
    "            esa_mean.append(np.nan)\n",
    "        else:\n",
    "            esa_mean.append(res_esa)\n",
    "\n",
    "        # find the GPM file\n",
    "        file_gpm = findfile(gpm_files, yyyymmdd)\n",
    "\n",
    "        precip7d.append(nearestneighbor_ncdf(file_gpm[0],\n",
    "                                             'precipitationCal', loc))\n",
    "        landslide7d_id.append(glc_state_gt2015.event_id[i])\n",
    "        # Append the date\n",
    "        precip7d_date.append(yyyymmdd)\n",
    "\n",
    "        precip.append(nearestneighbor_ncdf(file_gpm[0],\n",
    "                                           'precipitationCal', loc))\n",
    "\n",
    "        # Append countdown\n",
    "        count_down.append(countd)\n",
    "        countd -= 1\n",
    "\n",
    "    # Append the summary values for the 7 day period\n",
    "    smap_sm.append(np.nanmax(sm_max))\n",
    "    smap_wc.append(np.nanmax(vegwc_max))\n",
    "    esa_sm.append(np.nanmax(esa_mean))\n",
    "    smap_sm_7d.extend(sm_max)\n",
    "    esa_sm_7d.extend(esa_mean)\n",
    "\n",
    "    # Filter for low or too high precipitation values\n",
    "    if np.nansum(precip) < 0.4:\n",
    "        precip_accum.append(np.nan)\n",
    "        precip_max.append(np.nan)\n",
    "    else:\n",
    "        precip_accum.append(np.nansum(precip))\n",
    "        precip_max.append(np.nanmax(precip))\n",
    "\n",
    "# Create a soils and precip dataFrame\n",
    "landslide_df = pd.DataFrame(smap_sm,\n",
    "                            index=pd.to_datetime(landslide_date),\n",
    "                            columns=['smap_sm'])\n",
    "landslide_df['veg_water_content'] = smap_wc\n",
    "landslide_df['esa_sm_percent'] = esa_sm\n",
    "landslide_df['gpm_7day_accum_mm'] = precip_accum\n",
    "landslide_df['gpm_7day_max_mm'] = precip_max\n",
    "landslide_df['ksat_log10cm/hr'] = ksat_list\n",
    "\n",
    "# Add the Landslide metadata\n",
    "landslide_df['glc_lat'] = lat\n",
    "landslide_df['glc_lon'] = lon\n",
    "landslide_df['landslide_id'] = landslide_id\n",
    "landslide_df['landslide_category'] = landslide_cat\n",
    "landslide_df['landslide_trigger'] = landslide_trig\n",
    "landslide_df['landslide_size'] = landslide_sz\n",
    "\n",
    "# Create the 7day precipitation dataFrame\n",
    "landslide_precip7d_df = pd.DataFrame(precip7d,\n",
    "                                     index=pd.to_datetime(precip7d_date),\n",
    "                                     columns=['gpm_precip_mm'])\n",
    "landslide_precip7d_df['landslide_id'] = landslide7d_id\n",
    "landslide_precip7d_df['smap_sm'] = smap_sm_7d\n",
    "landslide_precip7d_df['esa_vol'] = esa_sm_7d\n",
    "\n",
    "\n",
    "# Add the cumulative precipitation\n",
    "accum = []\n",
    "for i, data in landslide_precip7d_df.groupby(\"landslide_id\"):\n",
    "    res = data['gpm_precip_mm'].cumsum().values\n",
    "    if res.max() > 0.4:\n",
    "        accum.extend(np.flip(data['gpm_precip_mm'].cumsum().values))\n",
    "    else:\n",
    "        accum.extend([np.nan]*periods)\n",
    "\n",
    "landslide_precip7d_df['gpm_7day_accum_mm'] = accum\n",
    "landslide_precip7d_df['days-to-landslide'] = count_down\n",
    "landslide_precip7d_df.index.names = ['date']\n",
    "\n",
    "# Add the normalized precipitation\n",
    "accum_norm = []\n",
    "for i, data in landslide_precip7d_df.groupby(\"landslide_id\"):\n",
    "    res = data['gpm_7day_accum_mm']/data['gpm_7day_accum_mm'].mean()\n",
    "    accum_norm.append(res.max())\n",
    "\n",
    "landslide_df['gpm_7day_accum_norm'] = accum_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68fcdc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 868 entries, 2015-05-28 to 2018-05-27\n",
      "Data columns (total 6 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   gpm_precip_mm      868 non-null    float64\n",
      " 1   landslide_id       868 non-null    int64  \n",
      " 2   smap_sm            468 non-null    float32\n",
      " 3   esa_vol            509 non-null    float64\n",
      " 4   gpm_7day_accum_mm  847 non-null    float64\n",
      " 5   days-to-landslide  868 non-null    int64  \n",
      "dtypes: float32(1), float64(3), int64(2)\n",
      "memory usage: 44.1 KB\n"
     ]
    }
   ],
   "source": [
    "landslide_precip7d_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32312b1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 124 entries, 2015-05-28 17:30:00 to 2018-06-02 00:00:00\n",
      "Data columns (total 13 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   smap_sm              121 non-null    float32\n",
      " 1   veg_water_content    124 non-null    float32\n",
      " 2   esa_sm_percent       76 non-null     float64\n",
      " 3   gpm_7day_accum_mm    121 non-null    float64\n",
      " 4   gpm_7day_max_mm      121 non-null    float64\n",
      " 5   ksat_log10cm/hr      123 non-null    float64\n",
      " 6   glc_lat              124 non-null    float64\n",
      " 7   glc_lon              124 non-null    float64\n",
      " 8   landslide_id         124 non-null    int64  \n",
      " 9   landslide_category   124 non-null    object \n",
      " 10  landslide_trigger    124 non-null    object \n",
      " 11  landslide_size       124 non-null    object \n",
      " 12  gpm_7day_accum_norm  121 non-null    float64\n",
      "dtypes: float32(2), float64(7), int64(1), object(3)\n",
      "memory usage: 12.6+ KB\n"
     ]
    }
   ],
   "source": [
    "landslide_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a59eea",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Add the IMERGE 30min resolution precipitation to the landslide_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a524e72",
   "metadata": {},
   "source": [
    "#### First, read the IMERGE 30min data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa52c4ff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jwitte/earth-analytics/data/capstone/precip_imerg/imerge/glc/imerge.2015.csv\n",
      "/Users/jwitte/earth-analytics/data/capstone/precip_imerg/imerge/glc/imerge.2016.csv\n",
      "/Users/jwitte/earth-analytics/data/capstone/precip_imerg/imerge/glc/imerge.2017.csv\n",
      "/Users/jwitte/earth-analytics/data/capstone/precip_imerg/imerge/glc/imerge.2018.csv\n",
      "/Users/jwitte/earth-analytics/data/capstone/precip_imerg/imerge/glc/imerge.2019.csv\n",
      "/Users/jwitte/earth-analytics/data/capstone/precip_imerg/imerge/glc/imerge.2020.csv\n"
     ]
    }
   ],
   "source": [
    "imerg_30min = get_imerg_hires(gpm_hires_files, glc_state_gt2015)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a233cfc",
   "metadata": {},
   "source": [
    "#### Loop over the newly created landslide_df\n",
    "- Add the sum and the max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f833ef5b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imerg_7day_sum = []\n",
    "imerg_7day_max = []\n",
    "imerg_7day_accum = []\n",
    "imerg_7day_date = []\n",
    "imerg_7day_id = []\n",
    "\n",
    "for i, ls_date in enumerate(landslide_df.index):\n",
    "\n",
    "    glc_date = pd.date_range(ls_date, periods=7,\n",
    "                             freq='-1D').strftime('%Y%m%d').to_list()\n",
    "\n",
    "    # selecting rows based on condition\n",
    "    rslt_df = imerg_30min[\n",
    "                    (imerg_30min['id'] == landslide_df['landslide_id'][i]) &\n",
    "                    imerg_30min['yyyymmdd'].isin(glc_date)\n",
    "                    ]\n",
    "    # first calculate the 7 day precipitation stats\n",
    "    if rslt_df.shape[0] > 0:\n",
    "        imerg_7day_sum.append(rslt_df['precipitation'].sum())\n",
    "        imerg_7day_max.append(rslt_df['precipitation'].max())\n",
    "        # append the 7 day daily values\n",
    "        imerg_7day_accum.extend(rslt_df.precipitation.resample('D').sum())\n",
    "        imerg_7day_date.extend(glc_date)\n",
    "        imerg_7day_id.extend([landslide_df['landslide_id'][i]]*7)\n",
    "    else:\n",
    "        imerg_7day_sum.append(np.nan)\n",
    "        imerg_7day_max.append(np.nan)\n",
    "        imerg_7day_accum.extend([np.nan]*7)\n",
    "        imerg_7day_date.extend(glc_date)\n",
    "        imerg_7day_id.extend([landslide_df['landslide_id'][i]]*7)\n",
    "\n",
    "landslide_df['imerg_7day_accum_mm'] = imerg_7day_sum\n",
    "landslide_df['imerg_7day_max_mm'] = imerg_7day_max\n",
    "landslide_df.index.name = 'date'\n",
    "\n",
    "landslide_precip7d_df['imerg_precip_mm'] = imerg_7day_accum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7db88a64",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gpm_precip_mm</th>\n",
       "      <th>landslide_id</th>\n",
       "      <th>smap_sm</th>\n",
       "      <th>esa_vol</th>\n",
       "      <th>gpm_7day_accum_mm</th>\n",
       "      <th>days-to-landslide</th>\n",
       "      <th>imerg_precip_mm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-05-28</th>\n",
       "      <td>0.130090</td>\n",
       "      <td>6996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.492840</td>\n",
       "      <td>8.421008</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-05-27</th>\n",
       "      <td>1.841735</td>\n",
       "      <td>6996</td>\n",
       "      <td>0.238765</td>\n",
       "      <td>49.121403</td>\n",
       "      <td>8.374829</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-05-26</th>\n",
       "      <td>1.864561</td>\n",
       "      <td>6996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.023668</td>\n",
       "      <td>8.374829</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-05-25</th>\n",
       "      <td>4.526540</td>\n",
       "      <td>6996</td>\n",
       "      <td>0.198632</td>\n",
       "      <td>27.058155</td>\n",
       "      <td>8.362926</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-05-24</th>\n",
       "      <td>0.011903</td>\n",
       "      <td>6996</td>\n",
       "      <td>0.237414</td>\n",
       "      <td>45.544178</td>\n",
       "      <td>3.836387</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-31</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>11457</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.645435</td>\n",
       "      <td>15.254440</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-30</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>11457</td>\n",
       "      <td>0.280904</td>\n",
       "      <td>26.691477</td>\n",
       "      <td>14.833284</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-29</th>\n",
       "      <td>0.034117</td>\n",
       "      <td>11457</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.477190</td>\n",
       "      <td>10.944297</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-28</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>11457</td>\n",
       "      <td>0.327707</td>\n",
       "      <td>45.889702</td>\n",
       "      <td>10.386200</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-27</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>11457</td>\n",
       "      <td>0.329295</td>\n",
       "      <td>28.804970</td>\n",
       "      <td>7.555600</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>868 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            gpm_precip_mm  landslide_id   smap_sm    esa_vol  \\\n",
       "date                                                           \n",
       "2015-05-28       0.130090          6996       NaN  34.492840   \n",
       "2015-05-27       1.841735          6996  0.238765  49.121403   \n",
       "2015-05-26       1.864561          6996       NaN  29.023668   \n",
       "2015-05-25       4.526540          6996  0.198632  27.058155   \n",
       "2015-05-24       0.011903          6996  0.237414  45.544178   \n",
       "...                   ...           ...       ...        ...   \n",
       "2018-05-31       0.000000         11457       NaN  18.645435   \n",
       "2018-05-30       0.000000         11457  0.280904  26.691477   \n",
       "2018-05-29       0.034117         11457       NaN  30.477190   \n",
       "2018-05-28       0.000000         11457  0.327707  45.889702   \n",
       "2018-05-27       0.000000         11457  0.329295  28.804970   \n",
       "\n",
       "            gpm_7day_accum_mm  days-to-landslide  imerg_precip_mm  \n",
       "date                                                               \n",
       "2015-05-28           8.421008                  7              NaN  \n",
       "2015-05-27           8.374829                  6              NaN  \n",
       "2015-05-26           8.374829                  5              NaN  \n",
       "2015-05-25           8.362926                  4              NaN  \n",
       "2015-05-24           3.836387                  3              NaN  \n",
       "...                       ...                ...              ...  \n",
       "2018-05-31          15.254440                  5              NaN  \n",
       "2018-05-30          14.833284                  4              NaN  \n",
       "2018-05-29          10.944297                  3              NaN  \n",
       "2018-05-28          10.386200                  2              NaN  \n",
       "2018-05-27           7.555600                  1              NaN  \n",
       "\n",
       "[868 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landslide_precip7d_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f58fa8",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Export the dataFrame to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce25a87a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# converting to CSV file\n",
    "output_file = os.path.join('data','glc_smap_esa_gpm_2015-2020_'+state+'.csv')\n",
    "landslide_df.to_csv(output_file)\n",
    "\n",
    "output_7d_file = os.path.join('data',\n",
    "                              'glc_smap_esa_gpm_2015-2020_7day_'+state+'.csv')\n",
    "landslide_precip7d_df.to_csv(output_7d_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34eb7fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
